{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New PyTorch Usage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxlRpyOqdqTq"
      },
      "source": [
        "Preliminary: Check for PyTorch Version\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdgpFzSJdnTw",
        "outputId": "0e2814fe-f587-429a-b6ef-b26829964227"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOJq56PCg8Gk",
        "outputId": "7e15ccb9-4286-4abb-d591-eeb2d5e735b8"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug 21 04:15:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM0WLF6-d-pv"
      },
      "source": [
        "# Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzx7t-Q3d8A2",
        "outputId": "d9cbc365-079d-4104-a3a8-4c9c144ff7fa"
      },
      "source": [
        "A = torch.tensor([[1., -1.], [1., -1.]])\n",
        "print(A)\n",
        "print(A.type)\n",
        "print(A.dtype)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1., -1.],\n",
            "        [ 1., -1.]])\n",
            "<built-in method type of Tensor object at 0x7fbb831440f0>\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zb7H7hHek8Q",
        "outputId": "ce952f68-2603-40fd-be0e-d565aa5f2c4b"
      },
      "source": [
        "# PyTorch works with numpy smoothly\n",
        "import numpy as np\n",
        "A = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
        "print(A)\n",
        "print(A.dtype)\n",
        "\n",
        "A = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)) # PyTorch inherits dtype from numpy\n",
        "print(A)\n",
        "print(A.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "torch.int64\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWR30Urif99p",
        "outputId": "6287ff13-362f-4fbd-8184-55545a835c7a"
      },
      "source": [
        "A = torch.ones([2, 2])\n",
        "print(A)\n",
        "\n",
        "A = A.cuda()\n",
        "print(A)\n",
        "\n",
        "# create tensor directly on the GPU\n",
        "cuda0 = torch.device('cuda:0')\n",
        "A = torch.ones([2, 4], dtype=torch.float32, device=cuda0)\n",
        "print(A)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiZ0oc1GgtGp"
      },
      "source": [
        "**Performance Tip**: Whenever possible, create tensors on GPUs directly, instead of transferring from CPU to GPU after creation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-fSqNJDimvz"
      },
      "source": [
        "#Tensor Operations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLQNegytgrUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130d2a82-15e9-4012-f8d6-8af64d9ffae6"
      },
      "source": [
        "# tensor operations\n",
        "A = torch.ones([2, 2])\n",
        "B = torch.tensor([[1, 3], [2, 4]])\n",
        "# component-wise operations\n",
        "print('A+B')\n",
        "print(A+B)\n",
        "print('A*B')\n",
        "print(A*B)\n",
        "\n",
        "# matrix multiplilcation\n",
        "print('matrix multiplication A*B')\n",
        "\n",
        "#print(torch.matmul(A, B)) # this line fails because matmul only supports 32-bit floats\n",
        "print(torch.matmul(A.float(), B.float())) # this works because of the conversion to float\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A+B\n",
            "tensor([[2., 4.],\n",
            "        [3., 5.]])\n",
            "A*B\n",
            "tensor([[1., 3.],\n",
            "        [2., 4.]])\n",
            "matrix multiplication A*B\n",
            "tensor([[3., 7.],\n",
            "        [3., 7.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I5iSLvaisjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccde092-bb2d-4635-bf33-9c4acc44301a"
      },
      "source": [
        "# concatenation\n",
        "print(A)\n",
        "print(B)\n",
        "print('along the row dimension')\n",
        "C = torch.cat([A, B], dim=0)\n",
        "print(C)\n",
        "\n",
        "print('along the column dimension')\n",
        "C = torch.cat([A, B], dim=1)\n",
        "print(C)\n",
        "\n",
        "print('create a new batch dimension and concatenate')\n",
        "As = A.unsqueeze(dim=0)\n",
        "Bs = B.unsqueeze(dim=0)\n",
        "print('As shape: ' + str(As.shape))\n",
        "print('Bs shape: ' + str(Bs.shape))\n",
        "C = torch.cat([As, Bs], dim=0)\n",
        "print(C)\n",
        "print(C.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1, 3],\n",
            "        [2, 4]])\n",
            "along the row dimension\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 3.],\n",
            "        [2., 4.]])\n",
            "along the column dimension\n",
            "tensor([[1., 1., 1., 3.],\n",
            "        [1., 1., 2., 4.]])\n",
            "create a new batch dimension and concatenate\n",
            "As shape: torch.Size([1, 2, 2])\n",
            "Bs shape: torch.Size([1, 2, 2])\n",
            "tensor([[[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 3.],\n",
            "         [2., 4.]]])\n",
            "torch.Size([2, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok7PNMb5kLRn"
      },
      "source": [
        "# Batch multiplication -- optimized for mini-batch operations\n",
        "A = torch.ones([2, 2, 3])\n",
        "A[1, :, :] = A[1, :, :] * 0.5\n",
        "print(A)\n",
        "print('A shape: ' + str(A.shape))\n",
        "\n",
        "B1 = torch.tensor([[1, 3], [2, 4], [4, 6]], dtype=torch.float32).unsqueeze(0)\n",
        "B2 = torch.tensor([[4, 3], [22, 4], [-4, 60]], dtype=torch.float32).unsqueeze(0)\n",
        "B = torch.cat([B1, B2], dim=0)\n",
        "print(B)\n",
        "print('B shape: ' + str(B.shape))\n",
        "D = torch.bmm(A, B)\n",
        "print(D)\n",
        "print(D.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgT5S_eamLwP"
      },
      "source": [
        "#Eigendecomposition\n",
        "# create orthgonal matrix\n",
        "U = torch.zeros([5, 5])\n",
        "torch.nn.init.orthogonal_(U) # any function ending in _ performs in-place modification\n",
        "print(U)\n",
        "\n",
        "# eigenvalues\n",
        "S = torch.diag(torch.tensor([2, 1.8, 0.9, 0.55, 0.3]))\n",
        "print(S)\n",
        "\n",
        "M = torch.matmul(torch.matmul(U,S), U.T)\n",
        "print(M)\n",
        "\n",
        "#verify positive definiteness\n",
        "for i in range(10):\n",
        "  v = torch.ones([5, 1]) # it is necessary to specify one more dimension in PyTorch\n",
        "  torch.nn.init.normal_(v)\n",
        "  ss = torch.matmul(torch.matmul(torch.transpose(v, 0, 1), M), v)\n",
        "  print(ss)\n",
        "\n",
        "L_complex, V_complex = torch.linalg.eig(M) # this by default returns complex numbers\n",
        "print(L_complex) # eigenvalues\n",
        "print(V_complex) # eigenvectors\n",
        "print(torch.view_as_real(L_complex)[:,0]) # real parts\n",
        "print(torch.view_as_real(V_complex)[:, :, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H90znHWFgUhg"
      },
      "source": [
        "### Tensor Expand\n",
        "\n",
        "Returns a new view of the self tensor with singleton dimensions expanded to a larger size. This does not allocate new memory. \n",
        "\n",
        "Any dimension of size 1 can be expanded to an arbitrary value without allocating new memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAUyj_uygTV8",
        "outputId": "eff6a5de-844b-4c9b-f91e-ce61eaaa68be"
      },
      "source": [
        "x = torch.tensor([[1], [2], [3]])\n",
        "x.size()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdIHulVugjel",
        "outputId": "33d9f808-6af8-4df6-96ce-41846656ddc0"
      },
      "source": [
        "x.expand(-1, 4)   # -1 means not changing the size of that dimension"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1],\n",
              "        [2, 2, 2, 2],\n",
              "        [3, 3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kpG9YATFnQG"
      },
      "source": [
        "We cannot expand any dimension whose size is not 1!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "n91Cp3Wtgv90",
        "outputId": "95b64408-9c0c-4816-849a-e63f645d4515"
      },
      "source": [
        "x.expand(4, 4) # Uh-oh!\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0e3ab91431b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Uh-oh!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [4, 4].  Tensor sizes: [3, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "xVMIjeZZg4C9",
        "outputId": "71d32281-3194-49df-e5ba-b9bcfdfa6f6d"
      },
      "source": [
        "x.expand(6, 4)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4b1391892c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (6) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [6, 4].  Tensor sizes: [3, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATJ_nTSAFWSp"
      },
      "source": [
        "What happens when you write to a tensor resulting from expansion?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h4pxK4FhIvD",
        "outputId": "8dc2ac95-42e2-4ea4-fc02-c99aa5bcf4d5"
      },
      "source": [
        "y = x.repeat(4, 3) # repeat the first dimension 4 times, yielding 12x1. This actually takes new memory\n",
        "print(y)\n",
        "y[1, 1] = 100\n",
        "print(y)\n",
        "x"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3],\n",
            "        [1, 1, 1],\n",
            "        [2, 2, 2],\n",
            "        [3, 3, 3]])\n",
            "tensor([[  1,   1,   1],\n",
            "        [  2, 100,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [2],\n",
              "        [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toThxEVa_HL1",
        "outputId": "cb0d3902-d17a-4678-9d72-f9b307c154c5"
      },
      "source": [
        "y = x.expand(3, 4)\n",
        "y[1,1]=100 # modifying the expanded tensor. This will allocate new memory. \n",
        "print(y)\n",
        "print(x)\n",
        "# However, PyTorch documentation explicitly warns against modifying the tensor\n",
        "# resulted from the expansion operation. So we probably shouldn't do this. "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  1,   1,   1],\n",
            "        [  2, 100,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3],\n",
            "        [  1,   1,   1],\n",
            "        [  2,   2,   2],\n",
            "        [  3,   3,   3]])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ3CxoR1qWDk"
      },
      "source": [
        "## Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXGc6mqAeTVJ"
      },
      "source": [
        "Two tensors are “broadcastable” if the following rules hold:\n",
        "\n",
        "Each tensor has at least one dimension.\n",
        "\n",
        "When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb6jrf14qVut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52094f47-6913-41ee-b2f5-b614e15cf4e7"
      },
      "source": [
        "x=torch.empty(5,7,3)\n",
        "y=torch.empty(5,7,3)\n",
        "# same shapes are always broadcastable (i.e. the above rules always hold)\n",
        "\n",
        "x=torch.empty((0,))\n",
        "y=torch.empty(2,2)\n",
        "# x and y are not broadcastable, because x does not have at least 1 dimension\n",
        "\n",
        "# can line up trailing dimensions\n",
        "x=torch.empty(5,3,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are broadcastable.\n",
        "# 1st trailing dimension: both have size 1\n",
        "# 2nd trailing dimension: y has size 1\n",
        "# 3rd trailing dimension: x size == y size\n",
        "# 4th trailing dimension: y dimension doesn't exist\n",
        "print(x+y)\n",
        "\n",
        "# but:\n",
        "x=torch.empty(5,2,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3\n",
        "x+y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[-1.5153e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34]],\n",
            "\n",
            "         [[ 3.0775e-41],\n",
            "          [ 3.0775e-41],\n",
            "          [ 3.0775e-41],\n",
            "          [ 3.0775e-41]],\n",
            "\n",
            "         [[ 1.5975e-43],\n",
            "          [ 1.4595e-39],\n",
            "          [ 1.8788e+31],\n",
            "          [ 1.7220e+22]]],\n",
            "\n",
            "\n",
            "        [[[-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34]],\n",
            "\n",
            "         [[ 3.3611e+21],\n",
            "          [ 2.6826e+23],\n",
            "          [ 2.1271e-07],\n",
            "          [ 1.3661e-05]],\n",
            "\n",
            "         [[ 5.2902e-08],\n",
            "          [ 1.4580e-19],\n",
            "          [ 1.1495e+24],\n",
            "          [ 3.0881e+29]]],\n",
            "\n",
            "\n",
            "        [[[-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34]],\n",
            "\n",
            "         [[ 2.3089e-12],\n",
            "          [ 1.9421e+31],\n",
            "          [ 2.7491e+20],\n",
            "          [ 6.1949e-04]],\n",
            "\n",
            "         [[ 1.9421e+31],\n",
            "          [ 2.7491e+20],\n",
            "          [ 2.3078e-12],\n",
            "          [ 7.1760e+22]]],\n",
            "\n",
            "\n",
            "        [[[-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34]],\n",
            "\n",
            "         [[ 3.4299e-06],\n",
            "          [ 5.3599e-08],\n",
            "          [ 1.6994e-04],\n",
            "          [ 6.7020e-10]],\n",
            "\n",
            "         [[ 1.7108e-04],\n",
            "          [ 1.6986e-07],\n",
            "          [ 2.3052e-12],\n",
            "          [ 2.6302e+20]]],\n",
            "\n",
            "\n",
            "        [[[-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34],\n",
            "          [-1.5144e+34]],\n",
            "\n",
            "         [[ 6.8737e-04],\n",
            "          [ 6.9374e-07],\n",
            "          [ 6.7368e-10],\n",
            "          [ 1.0664e-08]],\n",
            "\n",
            "         [[ 1.4580e-19],\n",
            "          [ 4.5450e+30],\n",
            "          [ 1.8524e+28],\n",
            "          [ 2.1715e-18]]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0dc949c501a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7cUdg-Iepq0"
      },
      "source": [
        "If two tensors x, y are “broadcastable”, the resulting tensor size is calculated as follows:\n",
        "\n",
        "If the number of dimensions of x and y are not equal, prepend 1 to the dimensions of the tensor with fewer dimensions to make them equal length.\n",
        "\n",
        "Then, for each dimension size, the resulting dimension size is the max of the sizes of x and y along that dimension.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMJ7vcm_e67z",
        "outputId": "4e5c938c-dba6-4b3c-f032-ba68a9c901d5"
      },
      "source": [
        "# can line up trailing dimensions to make reading easier\n",
        "x=torch.empty(5,1,4,1) # Returns a tensor filled with uninitialized data.\n",
        "y=torch.empty(  3,1,1)\n",
        "(x+y).size()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8BSeNiae9IG",
        "outputId": "b529ba61-557f-4623-b918-ba1c53e0d2ed"
      },
      "source": [
        "# but not necessary:\n",
        "x=torch.empty(1)\n",
        "y=torch.empty(3,1,7)\n",
        "(x+y).size()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "5rRTscP3e_lz",
        "outputId": "5a906092-6331-459f-e873-34fac4428183"
      },
      "source": [
        "x=torch.empty(5,2,4,1)\n",
        "y=torch.empty(3,1,1)\n",
        "(x+y).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7836c771d982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n1eNMRKfuix"
      },
      "source": [
        "### In-place semantics\n",
        "\n",
        "One complication is that in-place operations do not allow the in-place tensor to change shape as a result of the broadcast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AZgc4wafoDu",
        "outputId": "ce2bec16-b24d-4317-b214-010ac84e3f32"
      },
      "source": [
        "x=torch.empty(5,3,4,1)\n",
        "y=torch.empty(3,1,1)\n",
        "(x.add_(y)).size() # this replaces x with the result of the addition operation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 3, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "qhLFa6cJf0gW",
        "outputId": "660a5de3-9fca-4db2-b816-708706f8d588"
      },
      "source": [
        "x=torch.empty(1,3,1)\n",
        "y=torch.empty(3,1,7)\n",
        "(x.add_(y)).size()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-145e44306809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 3, 1] doesn't match the broadcast shape [3, 3, 7]"
          ]
        }
      ]
    }
  ]
}